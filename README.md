# Novel-Applications-of-Item-Response-Theory-for-Analysing-Data-Set-Complexity-and-Benchmark-Selection

This repository contains the .arff datasets, the corresponding dataset complexity measures (see data_complexity.dat), and the implemented classification methods (see classifiers.py) as described in the paper "Novel Applications of Item Response Theory for Analysing Data Set Complexity and Benchmark Selection".

The provided Python version (3.12.2) and the requirements.txt file refer to the environment used to run the script classifiers.py.
To set up the environment, please install the required dependencies using:

```bash
pip install -r requirements.txt
```

The experiments related to Item Response Theory (IRT) were conducted by Professor Telmo M. Silva Filho and are located in the 'IRT' directory. This section contains the scripts, data, and analyses carried out during the experiments, serving as the foundation for the studies and results presented in the published paper associated with this repository.


ðŸ“„ About the Paper

Title: Novel Applications of Item Response Theory for Analysing Data Set Complexity and Benchmark Selection

Authors: J.L.J. Pereira, A.A.A. Exposito De Queiroz, T.M. Silva Filho, A.C. Lorena, R.G. Mantovani, G.L. Pappa, R.B.C. PrudÃªncio.

Published in: Machine Learning, 2025, DOI: 10.1007/s10994-025-06873-3
