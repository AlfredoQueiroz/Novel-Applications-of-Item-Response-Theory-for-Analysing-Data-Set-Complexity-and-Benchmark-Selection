{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Beta3-IRT adapted from https://github.com/Manuelfjr/birt-gd\n",
    "\n",
    "from multiprocessing import Process, Queue, Value\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_probability as tfp\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class _viz:\n",
    "    def __init__(self, abi, dif, dis):\n",
    "        self.abilities = abi\n",
    "        self.difficulties = dif\n",
    "        self.discriminations = dis\n",
    "\n",
    "    def _split(self, *args):\n",
    "        (pij, predict, shape) = args\n",
    "        self.pij = pij\n",
    "        self.pijhat = pd.DataFrame( np.reshape(predict, (shape[0], shape[1])) )\n",
    "\n",
    "        shape = np.shape(self.pij)\n",
    "        try:\n",
    "            Y, X = np.reshape(self.pij.values,(shape[0]*shape[1], 1)), np.reshape(self.pijhat.values,(shape[0]*shape[1], 1))\n",
    "        except:\n",
    "            Y, X = np.reshape(self.pij,(shape[0]*shape[1], 1)), np.reshape(self.pijhat.values,(shape[0]*shape[1], 1))\n",
    "        return Y, X, self.pijhat\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"Get parameters\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        self : self objetc\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "        tuple of (abilities, difficulties, discrimination).\n",
    "        \"\"\"\n",
    "        return self.abilities, self.difficulties, self.discriminations\n",
    "\n",
    "    def irt(self, abilities, difficulties, discriminations):\n",
    "        \"\"\"calculating a probability (i) deduction from (j)\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        abilities :\n",
    "                Optimized ability estimation by gradient descent\n",
    "        difficulties :\n",
    "                Optimized difficulties estimation by gradient descent\n",
    "        discriminations :\n",
    "                Optimized discriminations estimation by gradient descent\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "        Calculate E[pij | abilities, difficulties, discriminations]\n",
    "        \"\"\"\n",
    "        alphaij = (abilities/difficulties)**(discriminations)\n",
    "        betaij = ( ((1 - abilities)/(1 - difficulties))**(discriminations) )\n",
    "        return alphaij/(alphaij + betaij)\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        \"\"\"Predict E[pij | abilities, difficulties, discrimination] = pij\n",
    "\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        X :\n",
    "            None\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "        return\n",
    "                y_pred = E[pij | abilities, difficulties, discrimination]\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        for d,a in zip(self.difficulties, self.discriminations):\n",
    "            for t in self.abilities:\n",
    "                y_pred.append(\n",
    "                    self.irt(\n",
    "                        abilities = t,\n",
    "                        difficulties = d,\n",
    "                        discriminations = a\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X=None, Y=None):\n",
    "        \"\"\"Score is Pseudo-R2\n",
    "\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        self.\n",
    "        X : array.\n",
    "            Contains pij adjusted.\n",
    "        Y : array.\n",
    "            Contains pij real.\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "            Calculate the Pseudo-R2 based a OLS model.\n",
    "        \"\"\"\n",
    "        model = LinearRegression()\n",
    "        model.fit(X,Y)\n",
    "        self.score = model.score(X, Y)\n",
    "        return self.score\n",
    "\n",
    "    def summary(self, show=False):\n",
    "        \"\"\"Summary of results\n",
    "\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        self.\n",
    "        show : boolean.\n",
    "            Show hyperparams (abilities, difficulties and discrimination).\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "            print summarize of the hyperparams and p_ij.\n",
    "        \"\"\"\n",
    "        abi, dif, dis = self.get_params()\n",
    "\n",
    "        out = '''\n",
    "        ESTIMATES\n",
    "        -----\n",
    "                        | Min      1Qt      Median   3Qt      Max      Std.Dev\n",
    "        Ability         | {0:.5f}  {1:.5f}  {2:.5f}  {3:.5f}  {4:.5f}  {5:.5f}\n",
    "        Difficulty      | {6:.5f}  {7:.5f}  {8:.5f}  {9:.5f}  {10:.5f}  {11:.5f}\n",
    "        Discrimination  | {12:.5f}  {13:.5f}  {14:.5f}  {15:.5f}  {16:.5f}  {17:.5f}\n",
    "        pij             | {18:.5f}  {19:.5f}  {20:.5f}  {21:.5f}  {22:.5f}  {23:.5f}\n",
    "        -----\n",
    "        Pseudo-R2       | {24:.5f}\n",
    "        '''.format(\n",
    "                    np.min(abi), np.quantile(abi,0.25),np.median(abi), np.quantile(abi,0.75),np.max(abi), np.std(abi),\n",
    "                    np.min(dif), np.quantile(dif,0.25),np.median(dif), np.quantile(dif,0.75),np.max(dif), np.std(dif),\n",
    "                    np.min(dis), np.quantile(dis,0.25),np.median(dis), np.quantile(dis,0.75),np.max(dis), np.std(dis),\n",
    "                    np.min(self.pijhat.values),  np.quantile(self.pijhat.values, 0.25), np.median(self.pijhat.values), np.quantile(self.pijhat.values,0.75),np.max(self.pijhat.values), np.std(self.pijhat.values),\n",
    "                    self.score\n",
    "                )\n",
    "        if show == False:\n",
    "            print(out)\n",
    "        else:\n",
    "            hyper = '''abilities: {},\\n\\t\\tdifficulti1es: {},\\n\\t\\tdiscriminations: {}\\n\\t-----\n",
    "                    '''.format(abi, dif, dis)\n",
    "            print(out + hyper)\n",
    "\n",
    "    def plot(self, xaxis=None, yaxis=None, kwargs={}, ann=False, font_size=12, font_ann_size=12):\n",
    "        \"\"\"Plot's of results\n",
    "\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        xaxis : {'discrimination','difficulty','ability'}.\n",
    "                x axis of plot.\n",
    "        yaxis : {'discrimination','difficulty', 'average_response', 'average_item'}\n",
    "                y axis of plot.\n",
    "        kwargs: dict.\n",
    "            other Matplotlib library arguments\n",
    "        ann   : boolean.\n",
    "            data points with annotations\n",
    "        font_size : int.\n",
    "            font size of x and y labels\n",
    "        font_ann_size : int.\n",
    "            font size of ann points\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "            Scatterplot of xaxis vs yaxis.\n",
    "        \"\"\"\n",
    "        pij = pd.DataFrame(np.reshape(self.predict(), (len(self.discriminations), len(self.abilities))))\n",
    "\n",
    "        sns.set_style('darkgrid')\n",
    "        plt.figure(figsize=(13,6))\n",
    "        if (xaxis == 'discrimination') and (yaxis == 'difficulty'):\n",
    "            sns.scatterplot(x=self.discriminations, y=self.difficulties, **kwargs)\n",
    "            if ann == True:\n",
    "                for i in range(pij.shape[0]):\n",
    "                    plt.text(x = self.discriminations[i]+0.007, y = self.difficulties[i]+0.007, s='n{}'.format(i+1), fontsize=font_ann_size)\n",
    "        elif (yaxis == 'discrimination') and (xaxis == 'difficulty'):\n",
    "            sns.scatterplot(x=self.difficulties, y=self.discriminations, **kwargs)\n",
    "            if ann == True:\n",
    "                sns.scatterplot(x=self.difficulties, y=self.discriminations, **kwargs)\n",
    "                for i in range(pij.shape[0]):\n",
    "                    plt.text(x = self.difficulties[i]+0.007, y = self.discriminations[i]+0.007, s='n{}'.format(i+1), fontsize=font_ann_size)\n",
    "        elif (xaxis == 'ability') and (yaxis == 'average_response'):\n",
    "            sns.scatterplot(x=self.abilities, y=pij.apply(np.mean,axis=0), **kwargs)\n",
    "            if ann == True:\n",
    "                sns.scatterplot(x=self.abilities, y=pij.apply(np.mean,axis=0), **kwargs)\n",
    "                for i in range(pij.shape[1]):\n",
    "                    plt.text(x = self.abilities[i]+0.003, y =pij.apply(np.mean,axis=0)[i]+0.003, s='{}'.format(self.pij.columns[i]), fontsize=font_ann_size)\n",
    "        elif (xaxis == 'difficulty') and (yaxis == 'average_item'):\n",
    "            sns.scatterplot(x=self.difficulties, y=pij.apply(np.mean,axis=1), **kwargs)\n",
    "            if ann == True:\n",
    "                for i in range(pij.shape[0]):\n",
    "                    plt.text(x = self.difficulties[i]+0.004, y =pij.apply(np.mean,axis=1)[i]+0.004, s='n{}'.format(i+1), fontsize=font_ann_size)\n",
    "        elif (xaxis == 'discrimination') and (yaxis == 'average_item'):\n",
    "            sns.scatterplot(x=self.discriminations, y=pij.apply(np.mean,axis=1), **kwargs)\n",
    "            if ann == True:\n",
    "                for i in range(pij.shape[0]):\n",
    "                    plt.text(x = self.discriminations[i]+0.004, y =pij.apply(np.mean,axis=1)[i]+0.004, s='n{}'.format(i+1), fontsize=font_ann_size)\n",
    "        elif xaxis == yaxis:\n",
    "            raise ValueError('xaxis and yaxis are the same')\n",
    "        elif xaxis not in ['discrimination','difficulty','ability'] or yaxis not in ['discrimination','difficulty', 'average_response', 'average_item']:\n",
    "            raise ValueError(f'{xaxis} or {yaxis} doesnt exists')\n",
    "        else:\n",
    "            raise ValueError(f'plotting {xaxis} vs {yaxis} is impossible.')\n",
    "        plt.title(f'{xaxis} vs {yaxis}', fontsize=font_size)\n",
    "        plt.xlabel(xaxis, fontsize=font_size)\n",
    "        plt.ylabel(yaxis, fontsize=font_size)\n",
    "\n",
    "    def boxplot(self, x=None, y=None, kwargs={}, font_size=12):\n",
    "        \"\"\"Boxplot's of results\n",
    "\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        x : ['discrimination','difficulty','ability', None].\n",
    "                x axis of plot.\n",
    "        y : ['discrimination','difficulty','ability', None]\n",
    "                y axis of plot.\n",
    "        kwargs: dict.\n",
    "            other Matplotlib library arguments.\n",
    "        font_size : int.\n",
    "            font size of x and y labels\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "            Boxplot of x axis vs y axis.\n",
    "        \"\"\"\n",
    "        abi = pd.DataFrame({'ability': self.abilities})\n",
    "        dif_dis = pd.DataFrame({'difficulty': self.difficulties, 'discrimination': self.discriminations})\n",
    "        sns.set_style('darkgrid')\n",
    "        plt.figure(figsize=(13,6))\n",
    "        if x == 'abilities':\n",
    "            if y == None:\n",
    "                bx = sns.boxplot(x=x,y=y, data=abi, **kwargs)\n",
    "            elif y == 'discrimination' or y == 'difficulty':\n",
    "                raise ValueError(f'the length of x is different from y.')\n",
    "            elif y == 'ability':\n",
    "                raise ValueError(f'both X and Y are the same')\n",
    "        elif x == 'difficulty':\n",
    "            if y == None or y == 'discrimination':\n",
    "                bx = sns.boxplot(x=x,y=y, data=dif_dis, **kwargs)\n",
    "            elif y == 'difficulty':\n",
    "                raise ValueError(f'both X and Y are the same')\n",
    "            elif y == 'ability':\n",
    "                raise ValueError(f'the length of x is different from y. ({dif_dis.shape[0], abi.shape[0]})')\n",
    "        elif x == 'discrimination':\n",
    "            if y == None or y == 'difficulty':\n",
    "                bx = sns.boxplot(x=x,y=y, data=dif_dis, **kwargs)\n",
    "            elif y == 'discrimination':\n",
    "                raise ValueError(f'both X and Y are the same')\n",
    "            elif y == 'ability':\n",
    "                raise ValueError(f'the length of x is different from y. ({dif_dis.shape[0], abi.shape[0]})')\n",
    "        elif x == None:\n",
    "            if y == 'ability':\n",
    "                bx = sns.boxplot(x=x,y=y, data=abi, **kwargs)\n",
    "            elif y == 'difficulty' or y == 'discrimination':\n",
    "                bx = sns.boxplot(x=x,y=y, data=dif_dis, **kwargs)\n",
    "            elif y == 'None':\n",
    "                raise ValueError(f'both X and Y are None')\n",
    "        elif y == None and (x not in ['ability', 'difficulty', 'discrimination']):\n",
    "            raise ValueError(f'y is None but {x} doesnot exist')\n",
    "        elif x == None and (y not in ['ability', 'difficulty', 'discrimination']):\n",
    "            raise ValueError(f'x is None but {y} doesnot exist')\n",
    "        elif x != None and y != None:\n",
    "            if (x == 'ability' and y == 'difficulty') or (x == 'difficulty' and y == 'ability'):\n",
    "                raise ValueError(f'the length of x is different from y.')\n",
    "        bx.set_ylabel(y,fontsize=font_size)\n",
    "        bx.set_xlabel(x,fontsize=font_size)\n",
    "\n",
    "class _irt(object):\n",
    "    def irt_three(self, thi, delj, aj):\n",
    "        \"\"\"Calculating a probability (i) deduction from (j) using Beta3-IRT\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        thi :\n",
    "                Parameter to be estimated from the abilitie for Beta3-IRT\n",
    "        delj :\n",
    "                Parameter to be estimated from the difficulty for Beta3-IRT\n",
    "        aj :\n",
    "                Other parameter of discrimination to be estimated to Beta3-IRT.\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "        Calculate E[pij | abilities, difficulties, discrimination = aj * bj]\n",
    "        \"\"\"\n",
    "        sig_thi, sig_delj = tf.math.sigmoid(thi), tf.math.sigmoid(delj)\n",
    "        param_aj = tf.convert_to_tensor(aj)\n",
    "\n",
    "        term1 = sig_delj / (1 - sig_delj)\n",
    "        term2 = (1 - sig_thi) / sig_thi\n",
    "        mult = tf.tensordot(term1, term2, axes=1)\n",
    "\n",
    "        est = 1 / (1 + mult ** (param_aj))\n",
    "        return est\n",
    "\n",
    "    def fit_three(self, *args):\n",
    "        \"\"\"Train with Gradient Descent\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        args : tuple containing\n",
    "                (queue, X, n_models, n_instances, epochs, lr, random_seed, n_inits, tol)\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "        self\n",
    "        \"\"\"\n",
    "        (queue, X, n_models, n_instances, epochs, lr, random_seed, n_inits, tol) = args\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(\n",
    "            random_seed\n",
    "        )\n",
    "\n",
    "        X = tf.constant(\n",
    "            X\n",
    "        )\n",
    "\n",
    "        thi = tf.Variable(\n",
    "            np.random.normal(0,1, size=(1, n_models)),\n",
    "            trainable=True, dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        delj = tf.Variable(\n",
    "            np.random.normal(0,1, size=(n_instances, 1)),\n",
    "            trainable=True, dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        if n_inits == 0:\n",
    "            aj = tf.Variable(\n",
    "                np.random.normal(1,1, size=(n_instances, 1)),\n",
    "                trainable=True, dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            aj = tf.Variable(\n",
    "                np.ones((n_instances, 1)),\n",
    "                trainable=True, dtype=tf.float32\n",
    "            )\n",
    "\n",
    "        t = 0\n",
    "        self.current_loss = 0\n",
    "        for _ in tqdm(range(epochs)):\n",
    "            if t < n_inits:\n",
    "                variables = [\n",
    "                    thi,\n",
    "                    delj\n",
    "                ]\n",
    "            else:\n",
    "                variables = [\n",
    "                    thi,\n",
    "                    delj,\n",
    "                    aj\n",
    "                ]\n",
    "\n",
    "            with tf.GradientTape() as g:\n",
    "                g.watch(variables)\n",
    "                pred = self.irt_three(thi = thi, delj = delj, aj = aj)\n",
    "                old_loss = self.current_loss\n",
    "                self.current_loss = _loss(\n",
    "                    X, pred\n",
    "                )\n",
    "\n",
    "            if np.abs(old_loss - self.current_loss) < tol:\n",
    "                print(f'Model converged at the {t}th epoch')\n",
    "                break\n",
    "\n",
    "            gradients = g.gradient(self.current_loss, variables)\n",
    "            if t < n_inits:\n",
    "                _thi, _delj = gradients\n",
    "            else:\n",
    "                _thi, _delj, _aj = gradients\n",
    "                aj.assign_sub(tf.math.scalar_mul(lr, _aj))\n",
    "\n",
    "            thi.assign_sub(tf.math.scalar_mul(lr, _thi))\n",
    "            delj.assign_sub(tf.math.scalar_mul(lr, _delj))\n",
    "\n",
    "            t += 1\n",
    "\n",
    "        abilities = tf.math.sigmoid(thi).numpy().flatten()\n",
    "        difficulties = tf.math.sigmoid(delj).numpy().flatten()\n",
    "        discriminations = tf.convert_to_tensor(aj).numpy().flatten()\n",
    "\n",
    "        parameters = (abilities, difficulties, discriminations)\n",
    "\n",
    "        queue.put(parameters)\n",
    "\n",
    "    def irt(self, abilities, difficulties, discriminations):\n",
    "        \"\"\"calculating a probability (i) deduction from (j)\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        abilities :\n",
    "                Optimized ability estimation by gradient descent\n",
    "        difficulties :\n",
    "                Optimized difficulties estimation by gradient descent\n",
    "        discriminations :\n",
    "                Optimized discriminations estimation by gradient descent\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "        Calculate E[pij | abilities, difficulties, discriminations]\n",
    "        \"\"\"\n",
    "        alphaij = (abilities/difficulties)**(discriminations)\n",
    "        betaij = ( ((1 - abilities)/(1 - difficulties))**(discriminations) )\n",
    "        return alphaij/(alphaij + betaij)\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        \"\"\"Predict E[pij | abilities, difficulties, discrimination] = pij\n",
    "\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        X :\n",
    "            None\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "        return\n",
    "                y_pred = E[pij | abilities, difficulties, discrimination]\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        for d,a in zip(self.difficulties, self.discriminations):\n",
    "            for t in self.abilities:\n",
    "                y_pred.append(\n",
    "                    self.irt(\n",
    "                        abilities = t,\n",
    "                        difficulties = d,\n",
    "                        discriminations = a\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "class Beta3(_viz,_irt):\n",
    "    \"\"\"Beta3-IRT with Gradient descent.\n",
    "    Read more in the https://github.com/Manuelfjr/BIRTGD .\n",
    "    Parameters:\n",
    "    -------------------------------------------------------\n",
    "    learning_rate : float, default=0.1\n",
    "        It's a learning rate to Gradient descent.\n",
    "    epochs : int, default=20\n",
    "        Numbers of epochs to fit the model.\n",
    "    n_models : int, default=20\n",
    "        Numbers of models to be evaluated.\n",
    "    n_instances : int, default=100\n",
    "        Numbers of instances to fit the models.\n",
    "    random_seed : int, default=1\n",
    "        Determines a random state to generation initial kicks.\n",
    "\n",
    "    n_inits : int, default=10\n",
    "        Determines the number of initializations.\n",
    "\n",
    "    n_workers : int, default=-1\n",
    "        Determines the number of CPUs to use.\n",
    "    tol : float, default=10**(-5)\n",
    "        Tolerance to converge epochs.\n",
    "\n",
    "    Attributes\n",
    "    -------------------------------------------------------\n",
    "    self.abilities : ResourceVariable of shape (n_models,)\n",
    "        It is the optimized estimate for the abilitie parameter.\n",
    "\n",
    "    self.difficulties : ResourceVariable of shape (n_instances,)\n",
    "        It is the optimized estimate for the difficulties parameter.\n",
    "    self.discriminations : ResourceVariable of shape (n_instances,)\n",
    "        It is the optimized estimate for the discrimination parameter.\n",
    "    Notes\n",
    "    -------------------------------------------------------\n",
    "    Example\n",
    "    -------------------------------------------------------\n",
    "    >>> from birt import BTHREE\n",
    "    >>> data = pd.DataFrame({'a': [0.99,0.89,0.87], 'b': [0.32,0.25,0.45]})\n",
    "    >>> bgd = BTHREE(n_models=2, n_instances=3, random_seed=1)\n",
    "    >>> bgd.fit(data)\n",
    "    100%|██████████| 5000/5000 [00:22<00:00, 219.50it/s]\n",
    "    <birt.BTHREE at 0x7f6131326c10>\n",
    "    >>> bsgd.abilities\n",
    "    array([0.90438306, 0.27729774], dtype=float32)\n",
    "    >>> bgd.difficulties\n",
    "    array([0.3760659, 0.5364428, 0.34256178], dtype=float32)\n",
    "    >>> bgd.discriminations\n",
    "    array([1.6690203, 0.9951777, 0.65577406], dtype=float32)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, learning_rate=1,\n",
    "        epochs=10000, n_models=20,\n",
    "        n_instances=100,\n",
    "        n_inits=1000, n_workers=-1,\n",
    "        random_seed=1, tol=10**(-5)\n",
    "    ):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.n_models = n_models\n",
    "        self.n_instances = n_instances\n",
    "        self.n_seed = random_seed\n",
    "        self.n_inits = n_inits\n",
    "        self.n_workers = n_workers\n",
    "        self.tol = tol\n",
    "        self._params = {\n",
    "            'learning_rate': learning_rate,\n",
    "            'epochs': epochs,\n",
    "            'n_models': n_models,\n",
    "            'n_instances': n_instances\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Compute BIRT Gradient Descent\n",
    "\n",
    "        Parameters\n",
    "        -------------------------------------------------------\n",
    "        X : list, array or tensor of shape (n_instances,n_models)\n",
    "\n",
    "        Returns\n",
    "        -------------------------------------------------------\n",
    "        self\n",
    "            Adjusted values of the parameters\n",
    "        \"\"\"\n",
    "        self.pij = X\n",
    "        queue = Queue()\n",
    "\n",
    "        args = (\n",
    "            queue, X, self.n_models,\n",
    "            self.n_instances,\n",
    "            self.epochs, self.lr, self.n_seed,\n",
    "            self.n_inits, self.tol\n",
    "        )\n",
    "\n",
    "        p = Process(target=super().fit_three, args=list(args))\n",
    "        p.start()\n",
    "        abi, dif, dis = queue.get()\n",
    "        p.join()\n",
    "\n",
    "        super().__init__(abi, dif, dis)\n",
    "\n",
    "        self.abilities = abi\n",
    "        self.difficulties = dif\n",
    "        self.discriminations = dis\n",
    "        X, Y, self.pijhat = self._split(self.pij, self.predict(), (len(self.discriminations), len(self.abilities)))\n",
    "        self.score(X, Y)\n",
    "        return self\n",
    "\n",
    "def _loss(y_true, y_pred):\n",
    "    \"\"\"Calculate Binary Cross Entropy (loss function)\n",
    "    Parameters\n",
    "    -------------------------------------------------------\n",
    "    y_true : tf.Tensor\n",
    "            Real valued Tensor containing the ground truth\n",
    "    y_pred : tf.Tensor\n",
    "            Real valued Tensor containing predictions\n",
    "    Returns\n",
    "    -------------------------------------------------------\n",
    "    EagerTensor with loss functions value\n",
    "    \"\"\"\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    return loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c676c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.util.multiprocessing import Pool\n",
    "\n",
    "def f(index):\n",
    "    data = pd.read_csv('responses/BAC_data_cleaned.csv', header=0, index_col=0)\n",
    "    D = data.values\n",
    "\n",
    "    return Beta3(\n",
    "        learning_rate=1,\n",
    "        epochs=50000, n_models=D.shape[1],\n",
    "        n_instances=D.shape[0],\n",
    "        n_inits=0, n_workers=-1,\n",
    "        random_seed=index,\n",
    "        tol=10**(-8)\n",
    "    ).fit(D)\n",
    "\n",
    "pool = Pool(5)\n",
    "\n",
    "b3_models = []\n",
    "\n",
    "for result in pool.map(f, range(10)):\n",
    "    b3_models.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb5f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26203dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('responses/BAC_data_cleaned.csv', header=0, index_col=0)\n",
    "\n",
    "concat_abi = pd.concat([pd.DataFrame(b.abilities, index=data.columns, columns=['ability']) for b in b3_models])\n",
    "concat_abi.groupby(concat_abi.index).mean().to_csv('responses/abilities-b3-beta-irt-gd-data-cleaned.csv')\n",
    "\n",
    "concat_dif = pd.concat([pd.DataFrame(b.difficulties, index=data.index, columns=['difficulty']) for b in b3_models])\n",
    "concat_dif.groupby(concat_dif.index).mean().to_csv('responses/difficulties-b3-beta-irt-gd-data-cleaned.csv')\n",
    "\n",
    "concat_dis = pd.concat([pd.DataFrame(b.discriminations, index=data.index, columns=['discrimination']) for b in b3_models])\n",
    "concat_dis.groupby(concat_dis.index).mean().to_csv('responses/discriminations-b3-beta-irt-gd-data-cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-irt-dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
